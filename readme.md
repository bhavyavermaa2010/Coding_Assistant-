# ğŸ’» Coding Assistant (Ollama + LangChain + Streamlit)

A **stateless AI-powered coding assistant** built using **Ollama**, **LangChain**, and **Streamlit**.  
This assistant answers **only coding & computer scienceâ€“related questions** and strictly follows the **selected domain**.

---

## ğŸš€ Features

- ğŸ”’ **Domain-locked responses**
  - General CS
  - Python
  - SQL
  - Machine Learning
  - Data Science
- ğŸ§  Stateless behavior (no memory stored)
- âš¡ Powered by **local LLM (Ollama â€“ LLaMA3)**
- ğŸ›ï¸ Clean Streamlit UI with sidebar controls
- ğŸ›‘ Automatically rejects out-of-domain questions

---

## ğŸ› ï¸ Tech Stack

- **Python 3.10+**
- **Streamlit**
- **LangChain**
- **Ollama (LLaMA3)**
- **LangSmith (Tracing & Monitoring)**
- **dotenv**

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ Coding_Assistant_Ollama.py # Main Streamlit app
â”œâ”€â”€ olla.ipynb # Experiment / testing notebook
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ .env # Environment variables (not pushed)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md




---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/coding-assistant-ollama.git
cd coding-assistant-ollama


2ï¸âƒ£ Create virtual environment (recommended)
python -m venv venv


Activate:

Windows

venv\Scripts\activate


Linux / macOS

source venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Setup environment variables

Create a .env file:

LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_PROJECT=Coding-Assistant


âš ï¸ Never push .env to GitHub

5ï¸âƒ£ Run Ollama (Required)

Make sure Ollama is installed and LLaMA3 model is pulled:

ollama pull llama3
ollama run llama3

6ï¸âƒ£ Run the Streamlit app
streamlit run Coding_Assistant_Ollama.py



ğŸ§  How It Works

User selects a domain from sidebar

Question is internally classified

If question âŒ does not belong to selected domain â†’ rejected

If valid âœ… â†’ answered using Ollama LLM

No chat history or memory is stored



ğŸ“Œ Example Use Cases

SQL queries & database concepts

Python coding problems

Machine Learning theory

Data Science workflows

Core Computer Science concepts



ğŸ” Limitations

No non-technical questions allowed

No cross-domain answers

No memory or personalization



## âš ï¸ Deployment Note

This application uses a locally hosted LLM via Ollama and is intended for local execution only.
Cloud deployment is not supported in the current version.


ğŸ‘¨â€ğŸ’» Author

Bhavya Verma
ğŸ’¡ AI / ML | Full Stack | Open Source Learner



