{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d50ff7b",
   "metadata": {},
   "source": [
    "### **LangChain Demo using Ollama**\n",
    "\n",
    "#### Objective:\n",
    "This notebook demonstrates how to:\n",
    "- Use **LangChain** with a **local LLM**\n",
    "- Build a **prompt pipeline**\n",
    "- Integrate it with a **Streamlit UI**\n",
    "- Track interactions using **LangSmith**\n",
    "\n",
    "---\n",
    "#### **Libraries Used**\n",
    "\n",
    "- `os` → To access environment variables\n",
    "- `dotenv` → To load API keys securely from `.env`\n",
    "- `langchain_community.llms` → To use Ollama LLM\n",
    "- `langchain_core.prompts` → To define prompt templates\n",
    "- `langchain_core.output_parsers` → To convert LLM output to string\n",
    "- `streamlit` → To build a simple web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c980e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "import streamlit as st\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322864d",
   "metadata": {},
   "source": [
    "**Loading Environment Variables**\n",
    "\n",
    "We store sensitive keys like:\n",
    "- `LANGCHAIN_API_KEY`\n",
    "- `LANGCHAIN_PROJECT`\n",
    "\n",
    "inside a `.env` file for security.\n",
    "\n",
    "`load_dotenv()` reads that file and loads variables into the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee0858c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0193799c",
   "metadata": {},
   "source": [
    "**LangSmith Tracking**\n",
    "\n",
    "LangSmith helps:\n",
    "- Trace prompts & responses\n",
    "- Debug chains\n",
    "- Monitor LLM behavior\n",
    "\n",
    "We enable tracing by setting environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3559880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7305b3",
   "metadata": {},
   "source": [
    "**Prompt Template (Core of LangChain)**\n",
    "\n",
    "A prompt template defines:\n",
    "- System message → LLM behavior\n",
    "- User message → Dynamic input\n",
    "\n",
    "LangChain separates prompt logic from model logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92aa718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\n",
    "                \"\"\"You are a medical diagnosis and treatment assistant.\n",
    "                    STRICT DOMAIN RULES (MUST FOLLOW):\n",
    "                    1. You may answer ONLY questions related to:\n",
    "                    - Diseases and medical conditions\n",
    "                    - Symptoms and causes\n",
    "                    - Diagnosis methods\n",
    "                    - Treatment options and medications\n",
    "                    2. If the question is NOT related to medical diagnosis or treatment, respond EXACTLY with:\n",
    "                    \"I can only answer questions related to medical diagnosis and treatment.\"\n",
    "                    3. Do NOT answer questions related to:\n",
    "                    - Programming, technology, law, finance, or general knowledge\n",
    "                    - Personal opinions, hypotheticals, or non-medical advice\n",
    "                    4. Do NOT guess, assume, or hallucinate information.\n",
    "                    5. Keep responses factual, concise, and clinically neutral.\n",
    "                    6. If information is insufficient, clearly state that more medical details are required.\n",
    "                \"\"\"),\n",
    "        \n",
    "        (\"user\", \"Question: {question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b75b60e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have fever'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = input(\"Enter what you have problem?\")\n",
    "input_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75991e9",
   "metadata": {},
   "source": [
    "**Ollama LLM (Gemma 2B)**\n",
    "\n",
    "Ollama runs LLMs locally.\n",
    "Here we use:\n",
    "- Model: `gemma:2b`\n",
    "- Lightweight & fast\n",
    "- No API cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dd50706",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce850f9",
   "metadata": {},
   "source": [
    "**Output Parser**\n",
    "\n",
    "LLMs return complex objects.\n",
    "`StrOutputParser` converts output into a plain string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e1566a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d93fb",
   "metadata": {},
   "source": [
    "**LangChain Pipeline (Prompt → LLM → Output)**\n",
    "\n",
    "The `|` operator chains components:\n",
    "Prompt → Model → Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91ebe426",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c82b241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fever is a common symptom of many illnesses. To provide a more accurate diagnosis and treatment plan, could you please provide more information about your symptoms?\n",
      "\n",
      "Please answer the following questions:\n",
      "\n",
      "1. What is your temperature in Celsius or Fahrenheit?\n",
      "2. How long have you had the fever?\n",
      "3. Are you experiencing any other symptoms such as headache, body aches, or difficulty breathing?\n",
      "4. Have you recently traveled or been exposed to someone with a similar illness?\n",
      "5. Do you have a history of chronic medical conditions or allergies?\n",
      "\n",
      "Once I have this information, I can provide more specific guidance on potential causes and treatment options.\n"
     ]
    }
   ],
   "source": [
    "if input_text:\n",
    "    print(chain.invoke({\"question\": input_text}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
